{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370fa7cc-6e16-4abe-978f-9472fe05db1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 21:10:42 WARN Utils: Your hostname, chuot-HP-Pavilion-Laptop-14-ce3xxx resolves to a loopback address: 127.0.1.1; using 192.168.1.5 instead (on interface wlo1)\n",
      "24/05/21 21:10:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/21 21:10:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/21 21:10:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')  # Adjust the path if Spark is installed elsewhere\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e6d42a9-d8fc-4066-a8a6-a6f15ab149ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/07/2024\n",
      "02/06/2024\n",
      "19/06/2024\n",
      "21/05/2024\n",
      "07/06/2024\n",
      "16/06/2024\n",
      "08/06/2024\n",
      "28/05/2024\n",
      "16/07/2024\n",
      "31/07/2024\n",
      "30/05/2024\n",
      "27/05/2024\n",
      "18/06/2024\n",
      "24/05/2024\n",
      "30/08/2024\n",
      "01/06/2024\n",
      "27/06/2024\n",
      "09/06/2024\n",
      "04/06/2024\n",
      "06/06/2024\n",
      "20/08/2024\n",
      "29/05/2024\n",
      "25/05/2024\n",
      "05/07/2024\n",
      "31/05/2024\n",
      "26/05/2024\n",
      "15/07/2024\n",
      "15/06/2024\n",
      "12/06/2024\n",
      "22/06/2024\n",
      "03/06/2024\n",
      "13/06/2024\n",
      "29/06/2024\n",
      "17/06/2024\n",
      "21/06/2024\n",
      "24/06/2024\n",
      "23/05/2024\n",
      "10/06/2024\n",
      "05/06/2024\n",
      "11/06/2024\n",
      "30/06/2024\n",
      "20/06/2024\n",
      "14/06/2024\n",
      "22/05/2024\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your JSON file\n",
    "from pyspark.sql.functions import col, udf, to_date, when, regexp_extract, explode, col, regexp_replace, to_timestamp, concat\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType\n",
    "import json\n",
    "json_file_path = 'vieclam24h.json'\n",
    "# Read the JSON file into a DataFrame\n",
    "df = spark.read.option(\"multiline\",\"true\").json(json_file_path)\n",
    "\n",
    "# df_exploded = df.select(explode(col(\"category\")).alias(\"unique_category\"))\n",
    "\n",
    "# unique_categories = df_exploded.select(\"unique_category\").distinct().collect()\n",
    "# print(len(unique_categories))\n",
    "# for row in unique_categories:\n",
    "#     pass\n",
    "#     print(row.unique_category)\n",
    "# unique_experience_df = df.select(\"experience\").distinct()\n",
    "\n",
    "# unique_experience_df.show()\n",
    "\n",
    "# from pyspark.sql.functions import col\n",
    "unique_values = df.select(col(\"expiration\")).distinct().collect()\n",
    "\n",
    "# In ra các giá trị duy nhất\n",
    "for row in unique_values:\n",
    "    print(row.expiration)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#rdd.toDF().select(\"salary\").show(1)\n",
    "\n",
    "# Salary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60b22f-12a0-49dd-8dea-3eff6c326da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary\n",
    "def parse_salary(salary):\n",
    "    if salary is None or salary.lower() == \"thỏa thuận\":\n",
    "        return json.dumps({\"type\": 2, \"min\": None, \"max\": None, \"fixed_value\": None})\n",
    "    elif \"triệu\" in salary:\n",
    "        salary = salary.replace(\" triệu\", \"\").replace(\",\", \".\").strip()\n",
    "        if \"-\" in salary:\n",
    "            min_salary, max_salary = salary.split(\"-\")\n",
    "            return json.dumps({\"type\": 1, \"min\": float(min_salary), \"max\": float(max_salary), \"fixed_value\": None})\n",
    "        else:\n",
    "            return json.dumps({\"type\": 0, \"min\": None, \"max\": None, \"fixed_value\": float(salary)})\n",
    "    return json.dumps({\"type\": 2, \"min\": None, \"max\": None, \"fixed_value\": None})\n",
    "\n",
    "parse_salary_udf = udf(parse_salary, StringType())\n",
    "df = df.withColumn(\"salary\", parse_salary_udf(col(\"salary\")))\n",
    "rdd = df.rdd.map(lambda row: row.asDict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83ab852a-f56f-494a-b761-93160c8efa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|experience|\n",
      "+----------+\n",
      "|        2 |\n",
      "|        1 |\n",
      "|        1 |\n",
      "|        1 |\n",
      "|         0|\n",
      "|         0|\n",
      "|        2 |\n",
      "|        1 |\n",
      "|        1 |\n",
      "|         0|\n",
      "|         0|\n",
      "|        1 |\n",
      "|        1 |\n",
      "|         0|\n",
      "|         0|\n",
      "|        1 |\n",
      "|        1 |\n",
      "|         0|\n",
      "|        2 |\n",
      "|         0|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Experience\n",
    "def transform_experience(df):\n",
    "    df = df.withColumn(\"experience\", when(col(\"experience\") == \"Chưa có kinh nghiệm\", 0).otherwise(col(\"experience\")))\n",
    "    \n",
    "    df = df.withColumn(\"experience\", regexp_replace(col(\"experience\"), \"(Dưới |Hơn |năm)\", \"\"))\n",
    "    return df\n",
    "\n",
    "transformed_df = transform_experience(df)\n",
    "\n",
    "# Hiển thị kết quả\n",
    "transformed_df.select(\"experience\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ae66f32-6776-460a-93ae-36b5a13332fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|type|\n",
      "+----+\n",
      "|   0|\n",
      "|   0|\n",
      "|   0|\n",
      "|   0|\n",
      "|   0|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Type\n",
    "# 0. Toàn thời gian cố định\n",
    "# 1. Bán thời gian cố định\n",
    "# 2. Toàn thời gian tạm thời\n",
    "# 3. Khác\n",
    "df = df.withColumn(\n",
    "    \"type\",\n",
    "     when(col(\"type\") == \"Toàn thời gian cố định\", 0)\n",
    "    .when(col(\"type\") == \"Bán thời gian cố định\", 1)\n",
    "    .when(col(\"type\") == \"Toàn thời gian tạm thời\", 2)\n",
    "    .when(col(\"type\") == \"Khác\", 3)\n",
    "    .otherwise(None)\n",
    ")\n",
    "df.select(\"type\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c3ac9d3-97b6-4319-bfad-ce79c09ef747",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5001/169793363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Expiration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expiration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expiration\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" 00:00:00\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dd/MM/yyyy HH:mm:ss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expiration\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lit' is not defined"
     ]
    }
   ],
   "source": [
    "# Expiration\n",
    "df = df.withColumn(\"expiration\", to_timestamp(concat(col(\"expiration\"), lit(\" 00:00:00\")), \"dd/MM/yyyy HH:mm:ss\"))\n",
    "df.select(\"expiration\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d4178e-c0be-4771-a834-e39150efa388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2369e-f885-4fbf-aafb-df35fb9e7f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
