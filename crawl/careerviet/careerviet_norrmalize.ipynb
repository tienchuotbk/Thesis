{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370fa7cc-6e16-4abe-978f-9472fe05db1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 10:24:08 WARN Utils: Your hostname, chuot-HP-Pavilion-Laptop-14-ce3xxx resolves to a loopback address: 127.0.1.1; using 192.168.1.14 instead (on interface wlo1)\n",
      "24/06/11 10:24:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/11 10:24:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')  # Adjust the path if Spark is installed elsewhere\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6d42a9-d8fc-4066-a8a6-a6f15ab149ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `category` cannot be resolved. Did you mean one of the following? [`age`, `logo`, `location`, `salary`, `sex`].;\n'Project ['category]\n+- Relation [age#0,benefit#1,certificate#2,company#3,description#4,experience#5,expiration#6,location#7,logo#8,province#9,requirement#10,role#11,salary#12,sex#13,title#14,type#15,update_time#16,url#17] json\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7783/1812171232.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# unique_experience_df.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# from pyspark.sql.functions import col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# In ra các giá trị duy nhất\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3225\u001b[0m         \u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m         \"\"\"\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `category` cannot be resolved. Did you mean one of the following? [`age`, `logo`, `location`, `salary`, `sex`].;\n'Project ['category]\n+- Relation [age#0,benefit#1,certificate#2,company#3,description#4,experience#5,expiration#6,location#7,logo#8,province#9,requirement#10,role#11,salary#12,sex#13,title#14,type#15,update_time#16,url#17] json\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your JSON file\n",
    "from pyspark.sql.functions import col, udf, to_date, when, regexp_extract, explode, col, regexp_replace, to_timestamp, concat, lit, trim\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType, ArrayType\n",
    "import json\n",
    "import re\n",
    "import pymongo\n",
    "json_file_path = 'careerviet.json'\n",
    "# Read the JSON file into a DataFrame\n",
    "df = spark.read.option(\"multiline\",\"true\").json(json_file_path)\n",
    "\n",
    "# df_exploded = df.select(explode(col(\"location\")).alias(\"unique_category\"))\n",
    "\n",
    "# unique_categories = df_exploded.select(\"unique_category\").distinct().collect()\n",
    "# print(len(unique_categories))\n",
    "# for row in unique_categories:\n",
    "#     pass\n",
    "#     print(row.unique_category)\n",
    "# unique_experience_df = df.select(\"location\").distinct()\n",
    "\n",
    "# unique_experience_df.show()\n",
    "# from pyspark.sql.functions import col\n",
    "unique_values = df.select(col(\"category\")).distinct().collect()\n",
    "\n",
    "# In ra các giá trị duy nhất\n",
    "for row in unique_values:\n",
    "    if row.category is None:\n",
    "        print(\"None ne\")\n",
    "    print(row.category)\n",
    "\n",
    "\n",
    "# print(df.size)\n",
    "\n",
    "\n",
    "#rdd.toDF().select(\"salary\").show(1)\n",
    "\n",
    "# Salary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6a971ac-af9d-454f-94ef-472ee6a852b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"multiline\",\"true\").json(json_file_path)\n",
    "# Salary\n",
    "def parse_salary(salary):\n",
    "    vnd_per_usd = 25\n",
    "    if salary is None:\n",
    "        return {\"type\": 0 }\n",
    "    elif (salary.strip().lower() == \"cạnh tranh\"):\n",
    "        return {\"type\": 3 }\n",
    "    elif \"VND\" in salary:\n",
    "            salary = salary.replace(\" VND\", \"\").replace(\" Tr\", \"\").replace(\",\", \".\").strip()\n",
    "            if \"-\" in salary:\n",
    "                min_salary, max_salary = salary.split(\"-\")\n",
    "                return {\"type\": 1, \"min\": float(min_salary), \"max\": float(max_salary) }\n",
    "            elif \"Trên\" in salary:\n",
    "                min_salary = salary.replace(\"Trên\", \"\").strip()\n",
    "                return {\"type\": 5, \"min\": float(min_salary)}\n",
    "            elif \"Lên đến\" in salary:\n",
    "                max_salary = salary.replace(\"Lên đến\", \"\").strip()\n",
    "                return {\"type\": 4, \"max\": float(max_salary)}\n",
    "    elif \"USD\" in salary:\n",
    "        salary = salary.replace(\" USD\", \"\").replace(\" Tr\", \"\").replace(\",\", \"\").strip()\n",
    "        if \"-\" in salary:\n",
    "            min_salary, max_salary = salary.split(\"-\")\n",
    "            return {\"type\": 1, \"min\": float(min_salary)* vnd_per_usd, \"max\": float(max_salary)* vnd_per_usd}\n",
    "        elif \"Trên\" in salary:\n",
    "            min_salary = salary.replace(\"Trên\", \"\").strip()\n",
    "            return {\"type\": 5, \"min\": float(min_salary)* vnd_per_usd}\n",
    "        elif \"Lên đến\" in salary:\n",
    "            max_salary = salary.replace(\"Lên đến\", \"\").strip()\n",
    "            return {\"type\": 4, \"min\": float(max_salary)* vnd_per_usd}\n",
    "    else:\n",
    "        return {\"type\": 0 }\n",
    "                \n",
    "# Age\n",
    "def parse_age(age):\n",
    "    if age is None or age == \"Không giới hạn tuổi\":\n",
    "        return { \"type\": 0 }\n",
    "    # age = age.strip().lower()\n",
    "    if \"-\" in age:\n",
    "        strip_age = age.strip()\n",
    "        min_age, max_age = age.strip().split(\"-\")\n",
    "        return { \"type\": 1, \"min\": int(min_age), \"max\": int(max_age) }\n",
    "    elif \"Trên\" in age:\n",
    "        min_age = age.replace(\"Trên \", \"\")\n",
    "        return { \"type\": 4, \"min\": int(min_age)}\n",
    "    elif \"Dưới\" in age:\n",
    "        max_age = age.replace(\"Dưới \", \"\")\n",
    "        return { \"type\": 3, \"min\": int(max_age)}  \n",
    "    else:\n",
    "        fixed = age.strip()\n",
    "        return { \"type\": 2, \"fixed\": int(fixed)}  \n",
    "    return { \"type\": 0 }\n",
    "\n",
    "# Experience\n",
    "def parse_experience(experience):\n",
    "    if experience is None or experience == \"Chưa có kinh nghiệm\":\n",
    "        return { \"type\": 0 }\n",
    "    if \"-\" in experience:\n",
    "        strip_experience = experience.replace(\"Năm\", \"\").strip()\n",
    "        min_exp, max_exp = strip_experience.split(\"-\")\n",
    "        return {\"type\": 1, \"min\": int(min_exp), \"max\": int(max_exp) }\n",
    "    elif \"Lên đến\" in experience:\n",
    "        strip_experience = experience.replace(\"Lên đến\", \"\").replace(\"Năm\", \"\").strip()\n",
    "        max = strip_experience\n",
    "        return { \"type\": 3, \"max\": int(max) }\n",
    "    elif \"Trên\" in experience:\n",
    "        strip_experience = experience.replace(\"Trên\", \"\").replace(\"Năm\", \"\").strip()\n",
    "        min = strip_experience\n",
    "        return { \"type\": 4, \"min\": int(min) }\n",
    "    else:\n",
    "        fixed = experience.replace(\"Năm\", \"\").strip()\n",
    "        return { \"type\": 2, \"fixed\": int(fixed)}\n",
    "    return { \"type\": 0 }\n",
    "\n",
    "# Expiration\n",
    "df = df.withColumn(\"expiration\", to_timestamp(concat(col(\"expiration\"), lit(\" 00:00:00\")), \"dd/MM/yyyy HH:mm:ss\"))\n",
    "\n",
    "# Update at\n",
    "df = df.withColumn(\"update_time\", to_timestamp(concat(col(\"update_time\"), lit(\" 00:00:00\")), \"dd/MM/yyyy HH:mm:ss\"))\n",
    "\n",
    "# Type\n",
    "def get_type_job(type):\n",
    "    if type == \"Nhân viên chính thức\":\n",
    "        return 0\n",
    "    elif type == \"Bán thời gian\":\n",
    "        return 2\n",
    "    elif type == \"Thời vụ/ Nghề tự do\":\n",
    "        return 1\n",
    "    elif type == \"Thực tập\":\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "def get_list_type_job(types):\n",
    "    # Thời vụ/ Nghề tự do, Thực tập\n",
    "    # type = types.split(\",\")\n",
    "    if types is None:\n",
    "        return []\n",
    "    return [get_type_job(word.strip()) for word in types.split(\",\")]\n",
    "\n",
    "\n",
    "classify_type_udf = udf(get_list_type_job, ArrayType(IntegerType()))\n",
    "df = df.withColumn(\"type\", classify_type_udf(col(\"type\")))\n",
    "\n",
    "# Role\n",
    "def classify_role(role):\n",
    "    if role is None:\n",
    "        return 0\n",
    "    role = role.strip()\n",
    "    if role == \"Nhân viên\":\n",
    "        return 0\n",
    "    elif role == \"Quản lý\" or role == \"Quản lý cấp trung\":\n",
    "        return 1\n",
    "    elif role == \"Cộng tác viên\":\n",
    "        return 6\n",
    "    elif role == \"Trưởng nhóm / Giám sát\":\n",
    "        return 5\n",
    "    elif role == \"Sinh viên/ Thực tập sinh\" or role == \"Mới tốt nghiệp\":\n",
    "        return 4\n",
    "    elif role == \"Giám đốc\" or role == \"Tổng giám đốc\":\n",
    "        return 2\n",
    "    elif role == \"Phó Giám đốc\":\n",
    "        return 3\n",
    "    elif role == \"Chuyên gia\":\n",
    "        return 7\n",
    "    else:\n",
    "        return 0\n",
    "classify_role_udf = udf(classify_role, IntegerType())\n",
    "df = df.withColumn(\"role\", classify_role_udf(col(\"role\")))\n",
    "\n",
    "def normalize_benefit(benefits):\n",
    "    return list(map(lambda benefit: re.sub(r'^[*\\-+]+', '', benefit).strip(), benefits))\n",
    "benefit_udf = udf(normalize_benefit, ArrayType(StringType()))\n",
    "df = df.withColumn(\"benefit\", benefit_udf(col(\"benefit\")))\n",
    "df = df.withColumn(\"requirement\", benefit_udf(col(\"requirement\")))\n",
    "df = df.withColumn(\"description\", benefit_udf(col(\"requirement\")))\n",
    "\n",
    "# location\n",
    "def normalize_location(locations):\n",
    "    arr = []\n",
    "    for location in locations:\n",
    "        parts = [part.strip() for part in location.split(',') if part.strip()]\n",
    "        if len(parts) >= 2:\n",
    "            province = parts[-1]\n",
    "            district = parts[-2]\n",
    "            address = ', '.join(parts[:-2])\n",
    "            arr.append({\"province\": province, \"district\": district, \"address\": address})\n",
    "        elif len(parts) == 1:\n",
    "            arr.append ({\"province\": parts[-1], \"district\": None, \"address\": None })\n",
    "        else: \n",
    "            arr.append({\"address\": None, \"district\": None, \"province\": None})\n",
    "    return arr\n",
    "\n",
    "rdd = df.rdd.map(lambda row: {\n",
    "    **row.asDict(),\n",
    "    \"salary\": parse_salary(row[\"salary\"]),\n",
    "    \"age\": parse_age(row[\"age\"]),\n",
    "    # \"location\": normalize_location(row[\"location\"]),\n",
    "    \"experience\": parse_experience(row[\"experience\"])\n",
    "})\n",
    "\n",
    "# df.select([\"role\", \"url\"]).show(30, False)\n",
    "\n",
    "# # Insert dữ liệu vào collection \"jobs\"\n",
    "# rdd.foreachPartition(insert_into_mongodb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c7a90-9d72-4f05-8a50-256723c19fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
